# Mini-RLHF-DPO-Alignment
Fine-tuning a small language model using Direct Preference Optimization (DPO)
